{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af9958e",
   "metadata": {},
   "source": [
    "## What I did here \n",
    "1. set working directory\n",
    "2. save all necessary files in WD (Daegu map, occurrence map, Landsat band data ....)\n",
    "3. calculate NDVI from Landsat national data\n",
    "4. extract the NDVI at occurrence location \n",
    "5.  Check occurrence count ( threshold more than 30: some researcher suggest 25 for for logistic regression )\n",
    "6.  call logistic regression model\n",
    "7. fit the occurrence with NDVI (we have just 38 data points may under fit)\n",
    "8. predict national occurrence map with NDVI \n",
    "9. crop for Daegu area \n",
    "10. Save raster data \n",
    "\n",
    "repeat for random presence absence data  from 4 to 10;\n",
    "repeat for random presence absence data from 4 to 10, splitting train test data and .piloting ROC curve;\n",
    "A simple logistic regression code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde70018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to free up space...\n",
      "Uninstall unused applications function placeholder\n",
      "Clear browser cache function placeholder\n",
      "Empty Recycle Bin or Trash function placeholder\n",
      "Space cleanup completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import platform\n",
    "\n",
    "def delete_temporary_files():\n",
    "    # Windows specific temporary files\n",
    "    if platform.system() == 'Windows':\n",
    "        try:\n",
    "            os.system('del /q/f/s %TEMP%\\*')\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting temporary files on Windows: {e}\")\n",
    "    # Unix-like temporary files\n",
    "    else:\n",
    "        try:\n",
    "            shutil.rmtree('/tmp')\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting temporary files on Unix-like system: {e}\")\n",
    "\n",
    "def delete_downloads():\n",
    "    downloads_folder = os.path.expanduser('~') + '/Downloads'\n",
    "    try:\n",
    "        for filename in os.listdir(downloads_folder):\n",
    "            file_path = os.path.join(downloads_folder, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {file_path} : {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing Downloads folder: {e}\")\n",
    "\n",
    "def uninstall_unused_applications():\n",
    "    # Add logic to uninstall unused applications here\n",
    "    print(\"Uninstall unused applications function placeholder\")\n",
    "\n",
    "def clear_browser_cache():\n",
    "    # Add logic to clear browser cache here\n",
    "    print(\"Clear browser cache function placeholder\")\n",
    "\n",
    "def empty_recycle_bin_trash():\n",
    "    # Add logic to empty Recycle Bin or Trash here\n",
    "    print(\"Empty Recycle Bin or Trash function placeholder\")\n",
    "\n",
    "def free_up_space():\n",
    "    print(\"Starting to free up space...\")\n",
    "    delete_temporary_files()\n",
    "    delete_downloads()\n",
    "    uninstall_unused_applications()\n",
    "    clear_browser_cache()\n",
    "    empty_recycle_bin_trash()\n",
    "    print(\"Space cleanup completed.\")\n",
    "\n",
    "# Run the function to free up space\n",
    "free_up_space()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0087f10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'C:/Users/IT/Downloads/2023'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Change the working directory\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/IT/Downloads/2023\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Verify the current working directory\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent working directory:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mgetcwd())\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'C:/Users/IT/Downloads/2023'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the working directory\n",
    "os.chdir('C:/Users/IT/Downloads/2023')\n",
    "\n",
    "# Verify the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f0421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f49de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from rasterio import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_meta['crs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1b4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the Landsat 9 NIR (Band 5) and Red (Band 4) bands\n",
    "nir_band_path = 'LC09_L1TP_114035_20230805_20230805_02_T1_B5.TIF'\n",
    "red_band_path = 'LC09_L1TP_114035_20230805_20230805_02_T1_B4.TIF'\n",
    "\n",
    "# Open the NIR band (Band 5)\n",
    "with rio.open(nir_band_path) as nir_src:\n",
    "    nir = nir_src.read(1).astype('float32')\n",
    "    nir_meta = nir_src.meta\n",
    "\n",
    "# Open the Red band (Band 4)\n",
    "with rio.open(red_band_path) as red_src:\n",
    "    red = red_src.read(1).astype('float32')\n",
    "\n",
    "# Calculate NDVI\n",
    "ndvi = (nir - red) / (nir + red)\n",
    "\n",
    "# Update metadata to reflect the number of layers\n",
    "ndvi_meta = nir_meta\n",
    "ndvi_meta.update({\"count\": 1})\n",
    "\n",
    "# # Save the NDVI image\n",
    "# ndvi_path = 'NDVI.TIF' # we will use this data to crop for daegu are too \n",
    "# with rio.open(ndvi_path, 'w', **ndvi_meta) as dst:\n",
    "#     dst.write(ndvi, 1)\n",
    "\n",
    "# Plot NDVI\n",
    "plt.imshow(ndvi, cmap='viridis', vmin=-1, vmax=1)\n",
    "plt.colorbar(label='NDVI')\n",
    "plt.title('NDVI from Landsat 9')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411ba7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nir_meta['crs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Shapefile and Extract NDVI Values\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Path to the shapefile containing examined points\n",
    "shapefile_path = 'Daegu_point_korea_127/Daegu_point_korea_127.dbf'\n",
    "\n",
    "# Read the shapefile using GeoPandas\n",
    "gdf_points = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Reproject points to match the NDVI image CRS if necessary\n",
    "gdf_points = gdf_points.to_crs(ndvi_meta['crs'])   \n",
    "\n",
    "# Extract NDVI values at examined points\n",
    "ndvi_values = []\n",
    "for point in gdf_points.geometry:\n",
    "    row, col = ~nir_meta['transform'] * (point.x, point.y)\n",
    "    row, col = int(row), int(col)\n",
    "    if 0 <= row < ndvi.shape[0] and 0 <= col < ndvi.shape[1]:\n",
    "        ndvi_values.append(ndvi[row, col])\n",
    "    else:\n",
    "        ndvi_values.append(np.nan)\n",
    "\n",
    "# Add NDVI values to GeoDataFrame\n",
    "gdf_points['ndvi'] = ndvi_values\n",
    "\n",
    "# # Print examined data points with their NDVI values\n",
    "# print(gdf_points)\n",
    "# gdf_points.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c87e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have data in pandas data frame we can fit different models setting predictor and responses \n",
    "gdf_points.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simply check the occurrences frequency\n",
    "#normally need more than 30 points\n",
    "\n",
    "sum(gdf_points['P__bengale']),sum(gdf_points['P__volans']),sum(gdf_points['N__caudatu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c5abd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we found there is only oe species that cross the thrreshold \n",
    "#o we use P__bengale data\n",
    "# Prepare data for logistic regression\n",
    "X = gdf_points[['ndvi']].dropna()  # Predictor\n",
    "y = gdf_points['P__bengale'][gdf_points['ndvi'].notna()]  # Response\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186091d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ln = LinearRegression()\n",
    "model_ln.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46cec5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict probabilities over the entire area (logistic)\n",
    "ndvi_flat = ndvi.flatten()\n",
    "ndvi_flat = ndvi_flat[~np.isnan(ndvi_flat)]  # Drop NaN values if any\n",
    "probs = model.predict_proba(ndvi_flat.reshape(-1, 1))[:, 1]\n",
    "# Reshape probabilities to match the NDVI shape\n",
    "prob_map = np.full_like(ndvi, fill_value=np.nan)\n",
    "prob_map.ravel()[~np.isnan(ndvi.ravel())] = probs\n",
    "# Plot probability map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(prob_map, cmap='viridis', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.title('Predictive Map of Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110683f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities over the entire area (Linear)\n",
    "# Flatten the NDVI array\n",
    "ndvi_flat = ndvi.flatten()\n",
    "# Remove NaN values\n",
    "ndvi_flat = ndvi_flat[~np.isnan(ndvi_flat)]\n",
    "# Predict using the linear regression model\n",
    "predictions = model_ln.predict(ndvi_flat.reshape(-1, 1))\n",
    "# Convert the predictions to probabilities using the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "probs = sigmoid(predictions)\n",
    "# Create a probability map with the same shape as the original NDVI array\n",
    "prob_map = np.full_like(ndvi, fill_value=np.nan)\n",
    "# Assign the predicted probabilities to the corresponding positions in the probability map\n",
    "prob_map.ravel()[~np.isnan(ndvi.ravel())] = probs\n",
    "# Plot the probability map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(prob_map, cmap='viridis', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.title('Predictive Map of Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe9606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see there are only presence data so if there is ndvi value, the is high probability \n",
    "#Let's make some absance area and fit again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad3ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "gdf_points['P_A_species']= [random.randint(0, 1) for _ in range(gdf_points.shape[0])]  # presence absance data \n",
    "sum(gdf_points['P_A_species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb48467",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gdf_points[['ndvi']].dropna()  # Predictor\n",
    "y = gdf_points['P_A_species'][gdf_points['ndvi'].notna()]  # Response\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f20300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities over the entire area\n",
    "ndvi_flat = ndvi.flatten()\n",
    "ndvi_flat = ndvi_flat[~np.isnan(ndvi_flat)]  # Drop NaN values if any\n",
    "probs = model.predict_proba(ndvi_flat.reshape(-1, 1))[:, 1]\n",
    "# Reshape probabilities to match the NDVI shape\n",
    "prob_map = np.full_like(ndvi, fill_value=np.nan)\n",
    "prob_map.ravel()[~np.isnan(ndvi.ravel())] = probs\n",
    "# Plot probability map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(prob_map, cmap='viridis', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.title('Predictive logistic Map of Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  let's crop Daegu area\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "# Step 1: Read the vector file and convert to the desired CRS\n",
    "daegu_boundary = gpd.read_file(\"Daegu/Daegu.dbf\")\n",
    "nir_meta = {'crs': ndvi_meta['crs']}  # Example CRS, replace with your actual CRS\n",
    "\n",
    "daegu_boundary = daegu_boundary.to_crs(nir_meta['crs'])\n",
    "\n",
    "# Step 2: Define the bounds and resolution for the raster\n",
    "# Assuming you have bounds and resolution from some source (replace with actual values)\n",
    "# Example bounds and resolution\n",
    "bounds = (daegu_boundary.total_bounds[0], daegu_boundary.total_bounds[1], daegu_boundary.total_bounds[2], daegu_boundary.total_bounds[3])\n",
    "resolution = (0.001, 0.001)  # Example resolution in degrees\n",
    "\n",
    "# Calculate the width and height of the raster\n",
    "width = int((bounds[2] - bounds[0]) / resolution[0])\n",
    "height = int((bounds[3] - bounds[1]) / resolution[1])\n",
    "\n",
    "# Step 3: Create a raster template\n",
    "transform = from_bounds(bounds[0], bounds[1], bounds[2], bounds[3], width, height)\n",
    "raster_template = rasterio.open('raster_template.tif', 'w', driver='GTiff', \n",
    "                                width=width, height=height, count=1, \n",
    "                                dtype=rasterio.uint8, \n",
    "                                crs=nir_meta['crs'], \n",
    "                                transform=transform)\n",
    "\n",
    "# Step 4: Rasterize the vector data into the raster template\n",
    "shapes = [(geom, 255) for geom in daegu_boundary.geometry]\n",
    "rasterized = features.rasterize(shapes, out_shape=(height, width), transform=transform,\n",
    "                                fill=0, default_value=255, dtype=rasterio.uint8)\n",
    "\n",
    "# # Write rasterized data to the raster template\n",
    "# raster_template.write(rasterized, 1)\n",
    "\n",
    "# Close the raster template\n",
    "# raster_template.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49158e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Daegu boundary shapefile (replace with  actual file path)\n",
    "daegu_boundary = gpd.read_file(\"Daegu/Daegu.dbf\").to_crs(nir_meta['crs']) \n",
    "# Plotting the boundary of Daegu\n",
    "fig, ax = plt.subplots(figsize=(10, 8))  # Optional: Adjust figure size\n",
    "daegu_boundary.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2)\n",
    "\n",
    "# Plotting the points on the same plot\n",
    "gdf_points.plot(ax=ax, color='red', markersize=5)\n",
    "\n",
    "# Adding titles and labels\n",
    "ax.set_title('Daegu Boundary and Points')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb04fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "daegu_boundary.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterize the cropped Daegu boundary to use it as a mask\n",
    "daegu_mask = features.rasterize(\n",
    "    [(geom, 1) for geom in daegu_boundary.geometry],\n",
    "    out_shape=rasterized.shape,\n",
    "    transform=rio.transform.from_bounds(*daegu_boundary.total_bounds, prob_map.shape[1], prob_map.shape[0]),\n",
    "    fill=0,\n",
    "    all_touched=True,\n",
    "    dtype=np.int16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(daegu_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterize the cropped Daegu boundary to use it as a mask\n",
    "daegu_mask = features.rasterize(\n",
    "    [(geom, 1) for geom in daegu_boundary.geometry],\n",
    "    out_shape=rasterized.shape,\n",
    "    transform=rio.transform.from_bounds(*daegu_boundary.total_bounds, prob_map.shape[1], prob_map.shape[0]),\n",
    "    fill=0,\n",
    "    all_touched=True,\n",
    "    dtype=np.int16,\n",
    ")\n",
    "\n",
    "# Apply the mask to prob_map (exclude zero values)\n",
    "prob_map_cropped = prob_map.copy()\n",
    "prob_map_cropped[daegu_mask == 0] = np.nan\n",
    "\n",
    "# Plot the cropped probability map\n",
    "plt.imshow(prob_map_cropped, cmap='viridis', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.title('Cropped Predictive Map for Daegu')\n",
    "plt.show()\n",
    "\n",
    "# Save the cropped probability map as a raster file\n",
    "output_file = 'cropped_prob1_map.tif'\n",
    "with rio.open(output_file, 'w', driver='GTiff', width=prob_map_cropped.shape[1], height=prob_map_cropped.shape[0], count=1, dtype=rio.float64, crs=rio.crs.CRS.from_epsg(4326), transform=rio.transform.from_bounds(*daegu_boundary.total_bounds, prob_map_cropped.shape[1], prob_map_cropped.shape[0])) as dst:\n",
    "    dst.write(prob_map_cropped, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a6985",
   "metadata": {},
   "source": [
    "## let's check linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gdf_points[['ndvi']].dropna()  # Predictor\n",
    "y = gdf_points['P_A_species'][gdf_points['ndvi'].notna()]  # Response\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities over the entire area\n",
    "ndvi_flat = ndvi.flatten()\n",
    "ndvi_flat = ndvi_flat[~np.isnan(ndvi_flat)]  # Drop NaN values if any\n",
    "# Predict using the linear regression model\n",
    "predictions = model_ln.predict(ndvi_flat.reshape(-1, 1))\n",
    "# Convert the predictions to probabilities using the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "probs = sigmoid(predictions)\n",
    "# Create a probability map with the same shape as the original NDVI array\n",
    "prob_map = np.full_like(ndvi, fill_value=np.nan)\n",
    "# Assign the predicted probabilities to the corresponding positions in the probability map\n",
    "prob_map.ravel()[~np.isnan(ndvi.ravel())] = probs\n",
    "# Plot the probability map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(prob_map, cmap='viridis', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.title('Predictive Linear national Map of Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6233ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterize the cropped Daegu boundary to use it as a mask (linear)\n",
    "daegu_mask = features.rasterize(\n",
    "    [(geom, 1) for geom in daegu_boundary.geometry],\n",
    "    out_shape=prob_map.shape,\n",
    "    transform=rio.transform.from_bounds(*daegu_boundary.total_bounds, prob_map.shape[1], prob_map.shape[0]),\n",
    "    fill=0,\n",
    "    all_touched=True,\n",
    "    dtype=np.int16,\n",
    ")\n",
    "\n",
    "# Apply the mask to prob_map (exclude zero values)\n",
    "prob_map_cropped = prob_map.copy()\n",
    "prob_map_cropped[daegu_mask == 0] = np.nan\n",
    "\n",
    "# Plot the cropped probability map\n",
    "plt.imshow(prob_map_cropped, cmap='viridis', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.title('Cropped Predictive Map for Daegu')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552e17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8402ae35",
   "metadata": {},
   "source": [
    "## Below we can do excercise checking accuracy using training testing approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f977f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check with test train data and ROC curve (A case for logistic regression )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b853e65d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we found there is only oe species that cross the thrreshold \n",
    "#o we use P__bengale data\n",
    "# Prepare data for logistic regression\n",
    "X = gdf_points[['ndvi']].dropna()  # Predictor\n",
    "y = gdf_points['P_A_species'][gdf_points['ndvi'].notna()]  # Response\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=42)\n",
    "# Fit logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Predict probabilities on test set\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities over the entire area\n",
    "ndvi_flat = ndvi.flatten()\n",
    "ndvi_flat = ndvi_flat[~np.isnan(ndvi_flat)]  # Drop NaN values if any\n",
    "probs = model.predict_proba(ndvi_flat.reshape(-1, 1))[:, 1]\n",
    "# Reshape probabilities to match the NDVI shape\n",
    "prob_map = np.full_like(ndvi, fill_value=np.nan)\n",
    "prob_map.ravel()[~np.isnan(ndvi.ravel())] = probs\n",
    "# Plot probability map\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(prob_map, cmap='viridis', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.title('Predictive Map with train_test approach of Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterize the cropped Daegu boundary to use it as a mask\n",
    "daegu_mask = features.rasterize(\n",
    "    [(geom, 1) for geom in daegu_boundary.geometry],\n",
    "    out_shape=prob_map.shape,\n",
    "    transform=rio.transform.from_bounds(*daegu_boundary.total_bounds, prob_map.shape[1], prob_map.shape[0]),\n",
    "    fill=0,\n",
    "    all_touched=True,\n",
    "    dtype=np.int16,\n",
    ")\n",
    "\n",
    "# Apply the mask to prob_map (exclude zero values)\n",
    "prob_map_cropped = prob_map.copy()\n",
    "prob_map_cropped[daegu_mask == 0] = np.nan\n",
    "\n",
    "# Plot the cropped probability map\n",
    "plt.imshow(prob_map_cropped, cmap='viridis', vmin=0, vmax=1)\n",
    "plt.colorbar(label='Probability')\n",
    "plt.title('Cropped Predictive Map for Daegu')\n",
    "plt.show()\n",
    "\n",
    "# Save the cropped probability map as a raster file\n",
    "output_file = 'cropped_prob1_map.tif'\n",
    "with rio.open(output_file, 'w', driver='GTiff', width=prob_map_cropped.shape[1], height=prob_map_cropped.shape[0], count=1, dtype=rio.float64, crs=rio.crs.CRS.from_epsg(4326), transform=rio.transform.from_bounds(*daegu_boundary.total_bounds, prob_map_cropped.shape[1], prob_map_cropped.shape[0])) as dst:\n",
    "    dst.write(prob_map_cropped, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple logistic regression code \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Generate random variables (features) and labels\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 2)  # Example features (random variables)\n",
    "y = (X.sum(axis=1) > 1.0).astype(int)  # Example labels based on a condition\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507d89f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
